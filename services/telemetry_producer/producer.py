import json
import time
import random
from datetime import datetime
from kafka import KafkaProducer
from kafka import KafkaConsumer
import threading

failure_mode = False
has_failed_once = False


KAFKA_BOOTSTRAP_SERVERS = "localhost:9092"

producer = KafkaProducer(
    bootstrap_servers=KAFKA_BOOTSTRAP_SERVERS,
    value_serializer=lambda v: json.dumps(v).encode("utf-8"),
)

SERVICE_NAME = "api-gateway"

def remediation_listener():
    global failure_mode, step

    consumer = KafkaConsumer(
        "remediations",
        bootstrap_servers="localhost:9092",
        value_deserializer=lambda m: json.loads(m.decode("utf-8")),
        auto_offset_reset="latest",
    )

    for msg in consumer:
        event = msg.value
        if event.get("status") == "FIX_APPLIED":
            print("ðŸŸ¢ Producer entering RECOVERY mode")
            failure_mode = False
            print("ðŸŸ¢ Producer stabilized after recovery")



def current_time():
    return datetime.utcnow().isoformat()


def generate_metrics(step: int):
    global failure_mode
    global has_failed_once

    latency = min(1500, 150 + step * 50)
    error_rate = min(50, step * 4)
    cpu = min(95, 30 + step * 5)

    if latency > 800 and not has_failed_once:
        failure_mode = True
        has_failed_once = True


    if not failure_mode:
        latency = max(200, latency)
        error_rate = max(0.5, error_rate)
        cpu = max(40, cpu)

    return {
        "service": SERVICE_NAME,
        "latency_ms": latency,
        "rps": 3000,
        "cpu": cpu,
        "error_rate": error_rate,
        "timestamp": current_time(),
    }


def generate_logs():
    global failure_mode

    if failure_mode:
        return [
            {
                "service": SERVICE_NAME,
                "level": "ERROR",
                "message": "Connection pool exhausted",
                "timestamp": current_time(),
            },
            {
                "service": SERVICE_NAME,
                "level": "ERROR",
                "message": "Upstream service timeout",
                "timestamp": current_time(),
            },
        ]

    return [
        {
            "service": SERVICE_NAME,
            "level": "INFO",
            "message": "Service operating normally",
            "timestamp": current_time(),
        }
    ]


def main():
    global step
    step = 0
    print("ðŸš€ Starting telemetry producer...")
    threading.Thread(target=remediation_listener, daemon=True).start()

    while True:
        metrics = generate_metrics(step)
        producer.send("metrics", metrics)
        print(f"[METRICS] {metrics}")

        logs = generate_logs()
        for log in logs:
            producer.send("logs", log)
            print(f"[LOG] {log}")
        if not has_failed_once:
            step += 1
        time.sleep(2)


if __name__ == "__main__":
    main()